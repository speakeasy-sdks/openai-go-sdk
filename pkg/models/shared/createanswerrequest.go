// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package shared

import (
	"bytes"
	"encoding/json"
	"errors"
)

type CreateAnswerRequestStopType string

const (
	CreateAnswerRequestStopTypeStr        CreateAnswerRequestStopType = "str"
	CreateAnswerRequestStopTypeArrayOfstr CreateAnswerRequestStopType = "arrayOfstr"
)

type CreateAnswerRequestStop struct {
	Str        *string
	ArrayOfstr []string

	Type CreateAnswerRequestStopType
}

func CreateCreateAnswerRequestStopStr(str string) CreateAnswerRequestStop {
	typ := CreateAnswerRequestStopTypeStr

	return CreateAnswerRequestStop{
		Str:  &str,
		Type: typ,
	}
}

func CreateCreateAnswerRequestStopArrayOfstr(arrayOfstr []string) CreateAnswerRequestStop {
	typ := CreateAnswerRequestStopTypeArrayOfstr

	return CreateAnswerRequestStop{
		ArrayOfstr: arrayOfstr,
		Type:       typ,
	}
}

func (u *CreateAnswerRequestStop) UnmarshalJSON(data []byte) error {
	var d *json.Decoder

	str := new(string)
	d = json.NewDecoder(bytes.NewReader(data))
	d.DisallowUnknownFields()
	if err := d.Decode(&str); err == nil {
		u.Str = str
		u.Type = CreateAnswerRequestStopTypeStr
		return nil
	}

	arrayOfstr := []string{}
	d = json.NewDecoder(bytes.NewReader(data))
	d.DisallowUnknownFields()
	if err := d.Decode(&arrayOfstr); err == nil {
		u.ArrayOfstr = arrayOfstr
		u.Type = CreateAnswerRequestStopTypeArrayOfstr
		return nil
	}

	return errors.New("could not unmarshal into supported union types")
}

func (u CreateAnswerRequestStop) MarshalJSON() ([]byte, error) {
	if u.Str != nil {
		return json.Marshal(u.Str)
	}

	if u.ArrayOfstr != nil {
		return json.Marshal(u.ArrayOfstr)
	}

	return nil, nil
}

type CreateAnswerRequest struct {
	// List of documents from which the answer for the input `question` should be derived. If this is an empty list, the question will be answered based on the question-answer examples.
	//
	// You should specify either `documents` or a `file`, but not both.
	//
	Documents []string `json:"documents,omitempty"`
	// List of (question, answer) pairs that will help steer the model towards the tone and answer format you'd like. We recommend adding 2 to 3 examples.
	Examples [][]string `json:"examples"`
	// A text snippet containing the contextual information used to generate the answers for the `examples` you provide.
	ExamplesContext string `json:"examples_context"`
	// If an object name is in the list, we provide the full information of the object; otherwise, we only provide the object ID. Currently we support `completion` and `file` objects for expansion.
	Expand []interface{} `json:"expand,omitempty"`
	// The ID of an uploaded file that contains documents to search over. See [upload file](/docs/api-reference/files/upload) for how to upload a file of the desired format and purpose.
	//
	// You should specify either `documents` or a `file`, but not both.
	//
	File      *string     `json:"file,omitempty"`
	LogitBias interface{} `json:"logit_bias,omitempty"`
	// Include the log probabilities on the `logprobs` most likely tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.
	//
	// The maximum value for `logprobs` is 5.
	//
	// When `logprobs` is set, `completion` will be automatically added into `expand` to get the logprobs.
	//
	Logprobs *int64 `json:"logprobs,omitempty"`
	// The maximum number of documents to be ranked by [Search](/docs/api-reference/searches/create) when using `file`. Setting it to a higher value leads to improved accuracy but with increased latency and cost.
	MaxRerank *int64 `json:"max_rerank,omitempty"`
	// The maximum number of tokens allowed for the generated answer
	MaxTokens *int64 `json:"max_tokens,omitempty"`
	// ID of the model to use for completion. You can select one of `ada`, `babbage`, `curie`, or `davinci`.
	Model string `json:"model"`
	// How many answers to generate for each question.
	N *int64 `json:"n,omitempty"`
	// Question to get answered.
	Question       string      `json:"question"`
	ReturnMetadata interface{} `json:"return_metadata,omitempty"`
	// If set to `true`, the returned JSON will include a "prompt" field containing the final prompt that was used to request a completion. This is mainly useful for debugging purposes.
	ReturnPrompt *bool `json:"return_prompt,omitempty"`
	// ID of the model to use for [Search](/docs/api-reference/searches/create). You can select one of `ada`, `babbage`, `curie`, or `davinci`.
	SearchModel *string `json:"search_model,omitempty"`
	// completions_stop_description
	Stop *CreateAnswerRequestStop `json:"stop,omitempty"`
	// What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
	Temperature *float64    `json:"temperature,omitempty"`
	User        interface{} `json:"user,omitempty"`
}
